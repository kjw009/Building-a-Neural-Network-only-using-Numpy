{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mnist Digit Dataset\n",
    "\n",
    "The MNIST digit dataset consist of 28x28 pixel hand drawn digits. Each row in the dataset consist of a sample. Each sample has 784 pixel values of 0 to 255 indicating the grey scale. This dataset will be used to train this projects neural network and another mnist digit test set will be used for validating the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MNIST_Digits](https://storage.googleapis.com/tfds-data/visualization/fig/mnist-3.0.1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
      "0      1       0       0       0       0       0       0       0       0   \n",
      "1      0       0       0       0       0       0       0       0       0   \n",
      "2      1       0       0       0       0       0       0       0       0   \n",
      "3      4       0       0       0       0       0       0       0       0   \n",
      "4      0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
      "0       0  ...         0         0         0         0         0         0   \n",
      "1       0  ...         0         0         0         0         0         0   \n",
      "2       0  ...         0         0         0         0         0         0   \n",
      "3       0  ...         0         0         0         0         0         0   \n",
      "4       0  ...         0         0         0         0         0         0   \n",
      "\n",
      "   pixel780  pixel781  pixel782  pixel783  \n",
      "0         0         0         0         0  \n",
      "1         0         0         0         0  \n",
      "2         0         0         0         0  \n",
      "3         0         0         0         0  \n",
      "4         0         0         0         0  \n",
      "\n",
      "[5 rows x 785 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import relevant modules for training the dataset\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Read training set using pandas\n",
    "df = pd.read_csv('mnist_train.csv')\n",
    "\n",
    "# Print first 5 rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each sample is a row from the dataset. Using matplotlib, a random sample from the dataset can be plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to plot a random sample from a dataset\n",
    "def plot_sample(dataset):\n",
    "    # Gather sample\n",
    "    sample = [dataset.iloc[np.random.randint(728), 1:]]\n",
    "    # Convert to numpy array and reshape it into a 28x28 matrix\n",
    "    sample = np.array([sample])\n",
    "    sample = sample.reshape((28,28))\n",
    "    # Plot the sample\n",
    "    plt.gray()\n",
    "    plt.imshow(sample, interpolation = 'nearest')\n",
    "    plt.show()\n",
    "\n",
    "# Call the function\n",
    "plot_sample(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test our dataset and prevent overfitting, 20% of the data will be used for testing the model.\n",
    "\n",
    "For this neural network , there will be three layers: The input layer will consist of 784 neurons indicating the pixel value of a sample; the hidden layer will consist of 10 neurons and the output layer will consist of 10 neurons indicating each possible digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, acc: 0.060, loss: 2.592, lr: 0.001\n",
      "epoch: 10, acc: 0.401, loss: 1.802, lr: 0.0009990109791306607\n",
      "epoch: 20, acc: 0.622, loss: 1.244, lr: 0.0009979143589897116\n",
      "epoch: 30, acc: 0.700, loss: 0.970, lr: 0.0009968201437414647\n",
      "epoch: 40, acc: 0.742, loss: 0.829, lr: 0.0009957283254836751\n",
      "epoch: 50, acc: 0.771, loss: 0.739, lr: 0.0009946388963486806\n",
      "epoch: 60, acc: 0.792, loss: 0.675, lr: 0.000993551848503214\n",
      "epoch: 70, acc: 0.809, loss: 0.626, lr: 0.000992467174148215\n",
      "epoch: 80, acc: 0.825, loss: 0.586, lr: 0.000991384865518643\n",
      "epoch: 90, acc: 0.837, loss: 0.555, lr: 0.0009903049148832926\n",
      "epoch: 100, acc: 0.799, loss: 0.609, lr: 0.0009892273145446092\n",
      "epoch: 110, acc: 0.846, loss: 0.523, lr: 0.0009881520568385063\n",
      "epoch: 120, acc: 0.859, loss: 0.491, lr: 0.0009870791341341834\n",
      "epoch: 130, acc: 0.864, loss: 0.472, lr: 0.0009860085388339465\n",
      "epoch: 140, acc: 0.869, loss: 0.457, lr: 0.0009849402633730264\n",
      "epoch: 150, acc: 0.872, loss: 0.446, lr: 0.000983874300219404\n",
      "epoch: 160, acc: 0.875, loss: 0.436, lr: 0.0009828106418736302\n",
      "epoch: 170, acc: 0.878, loss: 0.427, lr: 0.0009817492808686518\n",
      "epoch: 180, acc: 0.880, loss: 0.419, lr: 0.000980690209769636\n",
      "epoch: 190, acc: 0.882, loss: 0.412, lr: 0.0009796334211737967\n",
      "epoch: 200, acc: 0.884, loss: 0.405, lr: 0.0009785789077102233\n",
      "epoch: 210, acc: 0.886, loss: 0.399, lr: 0.0009775266620397072\n",
      "epoch: 220, acc: 0.887, loss: 0.394, lr: 0.0009764766768545735\n",
      "epoch: 230, acc: 0.889, loss: 0.388, lr: 0.0009754289448785103\n",
      "epoch: 240, acc: 0.890, loss: 0.384, lr: 0.0009743834588664023\n",
      "epoch: 250, acc: 0.891, loss: 0.379, lr: 0.000973340211604162\n",
      "epoch: 260, acc: 0.893, loss: 0.375, lr: 0.0009722991959085651\n",
      "epoch: 270, acc: 0.894, loss: 0.372, lr: 0.0009712604046270845\n",
      "epoch: 280, acc: 0.895, loss: 0.368, lr: 0.000970223830637728\n",
      "epoch: 290, acc: 0.896, loss: 0.365, lr: 0.0009691894668488743\n",
      "epoch: 300, acc: 0.897, loss: 0.362, lr: 0.0009681573061991112\n",
      "epoch: 310, acc: 0.898, loss: 0.359, lr: 0.000967127341657076\n",
      "epoch: 320, acc: 0.899, loss: 0.356, lr: 0.0009660995662212947\n",
      "epoch: 330, acc: 0.900, loss: 0.354, lr: 0.0009650739729200244\n",
      "epoch: 340, acc: 0.900, loss: 0.351, lr: 0.0009640505548110942\n",
      "epoch: 350, acc: 0.901, loss: 0.349, lr: 0.0009630293049817507\n",
      "epoch: 360, acc: 0.902, loss: 0.346, lr: 0.0009620102165484997\n",
      "epoch: 370, acc: 0.903, loss: 0.344, lr: 0.0009609932826569543\n",
      "epoch: 380, acc: 0.903, loss: 0.342, lr: 0.0009599784964816788\n",
      "epoch: 390, acc: 0.904, loss: 0.340, lr: 0.0009589658512260378\n",
      "epoch: 400, acc: 0.904, loss: 0.338, lr: 0.0009579553401220435\n",
      "epoch: 410, acc: 0.905, loss: 0.336, lr: 0.000956946956430205\n",
      "epoch: 420, acc: 0.906, loss: 0.334, lr: 0.000955940693439379\n",
      "epoch: 430, acc: 0.906, loss: 0.332, lr: 0.0009549365444666201\n",
      "epoch: 440, acc: 0.907, loss: 0.330, lr: 0.0009539345028570338\n",
      "epoch: 450, acc: 0.907, loss: 0.328, lr: 0.0009529345619836286\n",
      "epoch: 460, acc: 0.907, loss: 0.327, lr: 0.0009519367152471704\n",
      "epoch: 470, acc: 0.908, loss: 0.325, lr: 0.0009509409560760373\n",
      "epoch: 480, acc: 0.908, loss: 0.324, lr: 0.0009499472779260752\n",
      "epoch: 490, acc: 0.909, loss: 0.322, lr: 0.0009489556742804544\n",
      "epoch: 500, acc: 0.909, loss: 0.321, lr: 0.0009479661386495274\n"
     ]
    }
   ],
   "source": [
    "# Import NN classes \n",
    "from layer_dense import *\n",
    "from cost_functions import *\n",
    "from optimisers import *\n",
    "\n",
    "# Randomise df\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "# Split df into training and testing data\n",
    "df_test = df[0:8400]\n",
    "df_train = df[8400:42000]\n",
    "\n",
    "# Create training dataset\n",
    "X_train = df_train.iloc[:,1:]\n",
    "y_train = df_train.iloc[:, 0]\n",
    "\n",
    "# Convert X into a numpy array and ramdomise the dataset\n",
    "X_train = np.array(X_train)\n",
    "\n",
    "# Initiate hidden layer with 784 input values and 10 neurons\n",
    "hidden_layer = LayerDense(784, 10)\n",
    "# Initiate ReLU activation object\n",
    "relu = ActivationRelU()\n",
    "# Initiate output layer with 10 input values and 10 neurons \n",
    "output_layer = LayerDense(10, 10)\n",
    "# Initate softmax and cost functions with the ActivationSoftmaxCost object\n",
    "softmax_cost = ActivationSoftmaxCost()\n",
    "\n",
    "# Initiate optimiser object for back propagation \n",
    "sgd = Optimizer_SGD(learning_rate=0.001 ,decay=1.1e-4, momentum=100)\n",
    "\n",
    "# Train in epochs. 501 iterations.\n",
    "for epoch in range(501):\n",
    "    # Forward propagation\n",
    "    hidden_layer.forward(X_train)\n",
    "    relu.forward(hidden_layer.output)\n",
    "    output_layer.forward(relu.output)\n",
    "    \n",
    "    # Calculate error\n",
    "    cost = softmax_cost.forward(output_layer.output, y_train)\n",
    "    \n",
    "    # Calculate accuracy from output of softmax and y\n",
    "    predictions = np.argmax(softmax_cost.output, axis=1)\n",
    "    accuracy = np.mean(predictions==y_train)\n",
    "    \n",
    "    # Print statistics per set of epochs\n",
    "    if not epoch % 10:\n",
    "        print(f'epoch: {epoch}, ' +\n",
    "              f'acc: {accuracy:.3f}, ' +\n",
    "              f'loss: {cost:.3f}, ' +\n",
    "              f'lr: {sgd.current_learning_rate}')\n",
    "        \n",
    "    # Back propagation \n",
    "    softmax_cost.backward(softmax_cost.output, y_train)\n",
    "    output_layer.backward(softmax_cost.dinputs)\n",
    "    relu.backward(output_layer.dinputs)\n",
    "    hidden_layer.backward(relu.dinputs)\n",
    "    \n",
    "    # Update weights and biases\n",
    "    sgd.pre_update_params()\n",
    "    sgd.update_params(hidden_layer)\n",
    "    sgd.update_params(output_layer)\n",
    "    sgd.post_update_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NN achieved ~87% accuracy with the training set. This could be improved with more iteration, another layer or more neurons in the hidden layer - provided overfitting doesn't occur.\n",
    "\n",
    "Testing data will be used to test the model using df_test dataframe created with the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, acc: 0.900, loss: 0.347\n"
     ]
    }
   ],
   "source": [
    "# Create test data\n",
    "X_test = df_test.iloc[:,1:]\n",
    "y_test = df_test.iloc[:, 0]\n",
    "\n",
    "# Pass dataset through the model using the final params\n",
    "hidden_layer.forward(X_test)\n",
    "relu.forward(hidden_layer.output)\n",
    "output_layer.forward(relu.output)\n",
    "cost = softmax_cost.forward(output_layer.output, y_test)\n",
    "\n",
    "# Calculate accuracy and loss for the test dataset\n",
    "predictions = np.argmax(softmax_cost.output, axis = 1)\n",
    "# If y_test is a binary vector, convert to scalar values\n",
    "if len(y_test.shape) == 2:\n",
    "    y_test = np.argmax(y_test, axis = 1)\n",
    "accuracy = np.mean(predictions == y_test)\n",
    "\n",
    "# Print statistics\n",
    "print(f'test, acc: {accuracy:.3f}, loss: {cost:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can conclude that our model is accurate and major overfitting has not occurred.\n",
    "\n",
    "Kaggle has also provided data that hasn't been seen and has no labels to indicate the which digit the sample is. The model can be used to predict the digit and the sample can be plotted like above to check if the model was correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
      "0       0       0       0       0       0       0       0       0       0   \n",
      "1       0       0       0       0       0       0       0       0       0   \n",
      "2       0       0       0       0       0       0       0       0       0   \n",
      "3       0       0       0       0       0       0       0       0       0   \n",
      "4       0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
      "0       0  ...         0         0         0         0         0         0   \n",
      "1       0  ...         0         0         0         0         0         0   \n",
      "2       0  ...         0         0         0         0         0         0   \n",
      "3       0  ...         0         0         0         0         0         0   \n",
      "4       0  ...         0         0         0         0         0         0   \n",
      "\n",
      "   pixel780  pixel781  pixel782  pixel783  \n",
      "0         0         0         0         0  \n",
      "1         0         0         0         0  \n",
      "2         0         0         0         0  \n",
      "3         0         0         0         0  \n",
      "4         0         0         0         0  \n",
      "\n",
      "[5 rows x 784 columns]\n"
     ]
    }
   ],
   "source": [
    "# Read unseen data\n",
    "df = pd.read_csv('mnist_test.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAANNklEQVR4nO3dYaxU9ZnH8d9PaY1CE0HFZS1Ki75wrdFuAI2Q1ZWUIG+gmm5K4gYT4zUG1zZpzBo3sb7whWnWVkNMk9toSjddmibFyItGiwRFY9J4JaxASatFbG9BsJLIrb5ggacv7sFc8M6ZceacOXPv8/0kNzNznpk5Tyb8OGfmf875OyIEYPo7p+kGAPQHYQeSIOxAEoQdSIKwA0nM6OfKbPPTP1CziPBky3vastteafv3tt+x/VAv7wWgXu52nN32uZL+IOkbkkYlvSFpbUT8ruQ1bNmBmtWxZV8i6Z2I2B8RxyX9QtLqHt4PQI16Cftlkv484fFosewMtodsj9ge6WFdAHrUyw90k+0qfGY3PSKGJQ1L7MYDTeplyz4qaf6Ex1+WdLC3dgDUpZewvyHpKttfsf1FSd+WtKWatgBUrevd+Ig4Yft+SS9KOlfSsxGxt7LOAFSq66G3rlbGd3agdrUcVANg6iDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJNH1/OySZPuApDFJJyWdiIhFVTQFoHo9hb3wrxHx1wreB0CN2I0Hkug17CHpN7bftD002RNsD9kesT3S47oA9MAR0f2L7X+MiIO250raKuk/ImJHyfO7XxmAjkSEJ1ve05Y9Ig4Wt0ckPSdpSS/vB6A+XYfd9kzbXzp9X9IKSXuqagxAtXr5Nf5SSc/ZPv0+/xsRL1TSVTLnn39+af2SSy4pra9fv75l7Y477ih9bbuvcZs3by6t92JsbKy0vmHDhtL6Rx99VGU7017XYY+I/ZKuq7AXADVi6A1IgrADSRB2IAnCDiRB2IEkejqC7nOvLOkRdAsWLCitb9q0qbR+ww03VNjN1HH06NHS+s0331xa37t3b5XtTBm1HEEHYOog7EAShB1IgrADSRB2IAnCDiRB2IEkqrjgZAoXXnhhy9qaNWtKX/v000+X1tud4prVnDlzSuuLFy8urWcdZ2+FLTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJMH57B267777WtbajaM3aefOnaX1Dz74oNb1r1ixomWtuAx517Zv315aX758eU/vP1VxPjuQHGEHkiDsQBKEHUiCsANJEHYgCcIOJME4e+Giiy4qre/YsaNl7eqrr666nTO8+uqrpfUHHnigZe3dd98tfe2xY8e66qlTx48fb1mbMaO3yyl8/PHHpfUbb7yxZW06n+ve9Ti77WdtH7G9Z8KyOba32n67uJ1dZbMAqtfJbvxPJa08a9lDkrZFxFWSthWPAQywtmGPiB2Szp6HZ7WkjcX9jZLWVNsWgKp1+6Xp0og4JEkRccj23FZPtD0kaajL9QCoSO0XnIyIYUnD0mD/QAdMd90OvR22PU+Sitsj1bUEoA7dhn2LpHXF/XWSnq+mHQB1absbb3uTpFskXWx7VNL3JT0u6Ze275b0J0nfqrPJfli4cGFpvc6x9Keeeqq0/sgjj5TWx8bGqmxnypg5c2Zpnevxn6lt2CNibYtSzisDAFMUh8sCSRB2IAnCDiRB2IEkCDuQBFM2Fw4ePFhaf++991rWrrjiip7Wfe2115bWP/nkk57ev05Lly4trZ9zTn3bk36enj0dsGUHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQYZy+Mjo6W1vfs2dOy1us4+6233lpa37ZtW2n9sccea1kr61uSrrzyytL67bffXlq/9957S+t1jrO//PLLpfWRkZHa1j0VsWUHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSSYsrlDy5Yta1nbunVr6WvPO++8qtuBpAcffLC0/sQTT/Spk8HS9ZTNAKYHwg4kQdiBJAg7kARhB5Ig7EAShB1IgvPZO/Taa6+1rK1cubL0tU8++WRp/brrruumpY7Ykw65furDDz8srbeb9riXaZHb9dbuGJB25+rjTG237LaftX3E9p4Jyx61/Rfbu4q/VfW2CaBXnezG/1TSZJuuH0XE9cXfr6ttC0DV2oY9InZIOtqHXgDUqJcf6O63/Vaxmz+71ZNsD9kesc0FwYAGdRv2H0taKOl6SYcktTzjICKGI2JRRCzqcl0AKtBV2CPicEScjIhTkn4iaUm1bQGoWldhtz1vwsNvSmIMBBhwbcfZbW+SdIuki22PSvq+pFtsXy8pJB2QVH7x8GnulVdeKa2vWlU+MnnnnXeW1pcvX15av+mmm1rWtm/fXvraDRs2lNaPHi3/bbbdufyzZ7f8OYf51fusbdgjYu0ki5+poRcANeJwWSAJwg4kQdiBJAg7kARhB5LgUtJTwIwZ5YMml19+ecva/v37q27nDO+//35pfe7cubWt+7bbbiutv/jii7Wte5BxKWkgOcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJLSU8BJ06cKK3XOZZ+zTXXlNYvuOCC2taNarFlB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkGGdHqcWLF5fWZ82aVdu6T506VVo/efJkbeuejtiyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASjLOjMfaklzf/1O7du0vrL730UpXtTHttt+y259vebnuf7b22v1Msn2N7q+23i9vWE3EDaFwnu/EnJH0vIq6WdKOk9bb/SdJDkrZFxFWSthWPAQyotmGPiEMRsbO4PyZpn6TLJK2WtLF42kZJa2rqEUAFPtd3dtsLJH1d0m8lXRoRh6Tx/xBsTzqpl+0hSUM99gmgRx2H3fYsSb+S9N2IONbux5XTImJY0nDxHkzsCDSko6E321/QeNB/HhGbi8WHbc8r6vMkHamnRQBVaLtl9/gm/BlJ+yLihxNKWyStk/R4cft8LR2iUXVOudzP6cLR2W78Ukn/Lmm37V3Fsoc1HvJf2r5b0p8kfauWDgFUom3YI+I1Sa2+oC+vth0AdeFwWSAJwg4kQdiBJAg7kARhB5LgFFeUuuuuu5puARVhyw4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJcD47Btbw8HDTLUwrbNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IIlO5mefL+lnkv5B0ilJwxHxlO1HJd0j6YPiqQ9HxK/rahTNuOeee0rrL7zwQml95syZLWtjY2Olr3399ddL6/h8Ojmo5oSk70XETttfkvSm7a1F7UcR8d/1tQegKp3Mz35I0qHi/pjtfZIuq7sxANX6XN/ZbS+Q9HVJvy0W3W/7LdvP2p7d4jVDtkdsj/TWKoBedBx227Mk/UrSdyPimKQfS1oo6XqNb/mfmOx1ETEcEYsiYlHv7QLoVkdht/0FjQf95xGxWZIi4nBEnIyIU5J+ImlJfW0C6FXbsNu2pGck7YuIH05YPm/C074paU/17QGoiiOi/An2MkmvStqt8aE3SXpY0lqN78KHpAOS7i1+zCt7r/KVAehZRHiy5W3DXiXCDtSvVdg5gg5IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5BEv6ds/quk9yY8vrhYNogGtbdB7Uuit25V2dsVrQp9PZ/9Myu3Rwb12nSD2tug9iXRW7f61Ru78UAShB1IoumwDze8/jKD2tug9iXRW7f60luj39kB9E/TW3YAfULYgSQaCbvtlbZ/b/sd2w810UMrtg/Y3m17V9Pz0xVz6B2xvWfCsjm2t9p+u7iddI69hnp71PZfis9ul+1VDfU23/Z22/ts77X9nWJ5o59dSV99+dz6/p3d9rmS/iDpG5JGJb0haW1E/K6vjbRg+4CkRRHR+AEYtv9F0t8k/SwivlYs+4GkoxHxePEf5eyI+M8B6e1RSX9rehrvYraieROnGZe0RtJdavCzK+nr39SHz62JLfsSSe9ExP6IOC7pF5JWN9DHwIuIHZKOnrV4taSNxf2NGv/H0nctehsIEXEoInYW98cknZ5mvNHPrqSvvmgi7JdJ+vOEx6MarPneQ9JvbL9pe6jpZiZx6elptorbuQ33c7a203j301nTjA/MZ9fN9Oe9aiLsk01NM0jjf0sj4p8l3SZpfbG7is50NI13v0wyzfhA6Hb68141EfZRSfMnPP6ypIMN9DGpiDhY3B6R9JwGbyrqw6dn0C1ujzTcz6cGaRrvyaYZ1wB8dk1Of95E2N+QdJXtr9j+oqRvS9rSQB+fYXtm8cOJbM+UtEKDNxX1FknrivvrJD3fYC9nGJRpvFtNM66GP7vGpz+PiL7/SVql8V/k/yjpv5rooUVfX5X0f8Xf3qZ7k7RJ47t1/6/xPaK7JV0kaZukt4vbOQPU2/9ofGrvtzQerHkN9bZM418N35K0q/hb1fRnV9JXXz43DpcFkuAIOiAJwg4kQdiBJAg7kARhB5Ig7EAShB1I4u8Ysw9NpAGo/QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Model has predicted the digit is a 9\n"
     ]
    }
   ],
   "source": [
    "# Function to generate a random sample from a dataset\n",
    "def random_sample(dataset):\n",
    "    # Gather sample\n",
    "    sample = [dataset.iloc[np.random.randint(728)]]\n",
    "    # Convert to numpy array and reshape it into a 28x28 matrix\n",
    "    sample_array = np.array([sample])\n",
    "    sample_array = sample_array.reshape((28,28))\n",
    "    # Plot the sample\n",
    "    return sample, sample_array\n",
    "\n",
    "# Plot random sample from the dataset\n",
    "sample, sample_array = random_sample(df)\n",
    "plt.gray()\n",
    "plt.imshow(sample_array, interpolation = 'nearest')\n",
    "plt.show()\n",
    "\n",
    "# Convert sample into an numpy array\n",
    "sample = np.array(sample)\n",
    "\n",
    "# Need the activation softmax class as we are no longer calculating error\n",
    "softmax = ActivationSoftmax()\n",
    "\n",
    "# Pass sample to initiate forward propagation\n",
    "hidden_layer.forward(sample)\n",
    "relu.forward(hidden_layer.output)\n",
    "output_layer.forward(relu.output)\n",
    "softmax.forward(output_layer.output)\n",
    "\n",
    "print('The model predicted the digit is a', np.argmax(softmax.output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems with the model\n",
    "\n",
    "There are many improvements that can be made to the model to improve its accuracy. The obvious implementations are more layers, more neurons, more samples and more epoch iterations. However, even implementing all of these won't major problems the model has. Such as: generalisation to the dataset, the model becoming too dependent on any neurons, co-adoption and noise. This all can be implementing with only just using numpy however.\n",
    "\n",
    "Machine learning libraries like TensorFlow and PyTorch provide handling input data in tensors rather than single vectors for each sample. This adds another layer or even layers of information to use for a neural net"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
