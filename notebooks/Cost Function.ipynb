{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function \n",
    "\n",
    "After a forward propagation step, the neural network will need to calculate the error of the predicted values with respects to the labels. This error will be used to adjust the weights and biases of the neurons to produce more accurate predictions.\n",
    "\n",
    "The cost function used in this project will be the catergorical cross-entropy. Below is the class to calculate error using catergorical cross entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![catergorical cross entropy equation](http://androidkt.com/wp-content/uploads/2021/05/Selection_098.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to calculate error of an output\n",
    "class Cost:\n",
    "# Takes in the output layer values and the correct labels for the samples\n",
    "    def calculate(self, output, y):\n",
    "        # Calculate the losses for the corresponding sample in the set\n",
    "        costs = self.forward(output, y)\n",
    "        # Calculate mean loss in the sample\n",
    "        mean_cost = np.mean(costs)\n",
    "        # Return loss\n",
    "        return mean_cost\n",
    "\n",
    "# Catergorical cross entropy class that will inherit the base Cost class\n",
    "class CategoricalCrossEntropy(Cost):\n",
    "# Calculate the error using the predicted values from the output and \n",
    "# its corrresponding labels\n",
    "    def forward(self, y_pred, y_true):\n",
    "        samples = len(y_pred)\n",
    "         # Clip the predicted values to prevent error caused by inf\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "        # If the y_true are scalar values else use one-hot encoded labels\n",
    "        if len(y_true.shape) == 1:\n",
    "        # Retrieve the highest probability from each sample output from y_pred\n",
    "            confidences = y_pred_clipped[range(samples), y_true]\n",
    "        elif len(y_true.shape) == 2:\n",
    "            confidences = np.sum(y_pred_clipped * y_true, axis=1)\n",
    "        \n",
    "        # Calculate negative log of the confidences and return the value\n",
    "        negative_log_confidences = -np.log(confidences)\n",
    "        return negative_log_confidences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes will be tested using a spiral data. This will be imported along with the classes needed for forward propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 1.0986109788003033\n"
     ]
    }
   ],
   "source": [
    "# Import relavant modules\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Append file path to system's path \n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Import forward propagation classes and spiral data function\n",
    "from neuralNetworkClasses.forward_propagation_classes import *\n",
    "from spiral_data import spiral_data\n",
    "\n",
    "# Create a output layer to produce values to test the above classes\n",
    "X, y = spiral_data(100, 3)\n",
    "hidden_layer = LayerDense(2, 3)\n",
    "ReLU = ActivationReLU()\n",
    "output_layer = LayerDense(3, 3)\n",
    "softmax = ActivationSoftmax()\n",
    "hidden_layer.forward(X)\n",
    "ReLU.activate(hidden_layer.output)\n",
    "output_layer.forward(ReLU.output)\n",
    "softmax.activate(output_layer.output)\n",
    "\n",
    "# Create an instance of the CatergoricalCrossEntropy class\n",
    "cost_function = CategoricalCrossEntropy()\n",
    "# Parse the outer layer values and labels of the samples as arguments\n",
    "cost = cost_function.calculate(softmax.output, y)\n",
    "\n",
    "# Print cost value\n",
    "print('Cost:', cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected the cost is high as the model is random."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "06d3ad103a38a5e5980b0a2ddf222334b9b3630c94a7e75a8e45e8afe280f469"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
