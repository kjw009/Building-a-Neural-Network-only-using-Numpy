{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Basics \n",
    "\n",
    "The figure below is a simple neural network that has 3 layers: a input layer with 3 neurons, a hidden layer with 5 neurons and an output layer with two neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SimpleNeuralNetwork](https://miro.medium.com/max/1400/0*a_tr0gvjHtW9haUo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every neuron in each of the layers has a unique connection with the neurons in its adjacent layers. Neurons in a layer will take in values from the previous layer to produce an output for the next. The output is a multiplication of the inputs with the weight of the connection. Each neuron has a unique weight that corresponds to a unique connection and is multiplied with input value of the neuron that is connected.\n",
    "\n",
    "Below represents how the outer layer will produce its output values by using the input values from the hidden layer in the figure above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.5, 7.6499999999999995]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The below code is trying to replicate the output layer of the  neural network \n",
    "in the above figure.The inputs, weights and biases are arbituary.\n",
    " \"\"\"\n",
    "# Initialise the input values. 1 input value for each neuron\n",
    "inputs = [1.0, 2.0, 3.0, 4.0, 5.0] # There are five neurons in the hidden layer hence there are three input values.\n",
    "# Initialise the weights for each in the outer layer. \n",
    "# Each weight corresponds to a unique connection that the output layer neuron has\n",
    "weights1 = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "weights2 = [0.11, 0.21,0.31, 0.41, 0.51]\n",
    "# Initialise the bias values for each output neuron\n",
    "bias1 = 1\n",
    "bias2 = 2\n",
    "\"\"\"\n",
    "The output values for the hidden layer will be multiplication of the values of \n",
    "the  neurons in hidden/previous layer. The output will be a list of 2 values\n",
    "that corresponds to the value of the neuron in that layer\n",
    "\"\"\"\n",
    "# Calculate the values for the output layer\n",
    "output = [\n",
    "inputs[0]*weights1[0] + inputs[1]*weights1[1] + inputs[2]*weights1[2] + \\\n",
    "inputs[3]*weights1[3] + inputs[4]*weights1[4] + bias1,\n",
    "inputs[0]*weights2[0] + inputs[1]*weights2[1] + inputs[2]*weights2[2] + \\\n",
    "inputs[3]*weights2[3] + inputs[4]*weights2[4] + bias2 \n",
    "]\n",
    "\n",
    "# Print out the value of the outer layer\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outer layer produced two values that belongs to each neuron in its layer. A cleaner code is written below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.5, 7.6499999999999995]\n"
     ]
    }
   ],
   "source": [
    "inputs = [1.0, 2.0, 3.0, 4.0, 5.0]\n",
    "# Weights is a 2D array of values that belong to each neuron in the outer layer\n",
    "weights = [[0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "          [0.11, 0.21,0.31, 0.41, 0.51]]\n",
    "# Both bias values is now in the same list\n",
    "biases = [1,2]\n",
    "\n",
    "# Initialise values for output layer\n",
    "layer_outputs = []\n",
    "# Loop through the set of weights and each bias values declared above\n",
    "for neuron_weights, neuron_bias in zip(weights, biases):\n",
    "    neuron_output = 0 # Initialise neuron value\n",
    "# Loop throught inputs declared above and neuron_weights for each neuron\n",
    "    for n_input, weight in zip(inputs, neuron_weights):\n",
    "# Increment neuron_output by the multiplication of input and weight\n",
    "        neuron_output += n_input * weight\n",
    "# Increment neuron_output by the bias\n",
    "    neuron_output += neuron_bias\n",
    "# Append layer_outputs with the final neuron_output value\n",
    "    layer_outputs.append(neuron_output)\n",
    "\n",
    "print(layer_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example above multiplies the corresponding inputs and weights to produce an output. In a real neural network, the mutiplication will be dot product.\n",
    "\n",
    "The inputs variable is 1 dimensional and is a vector. The weights is 2 dimensional and is a matrix. Multiplying both is called the dot product. The code will now look like this below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.5  7.65]\n"
     ]
    }
   ],
   "source": [
    "# Import numpy to handle arrays\n",
    "import numpy as np\n",
    "\n",
    "# Weights comes first as the argument due to shape. You can't multiply a vector with a matrix.\n",
    "layer_outputs = np.dot(weights, inputs) + biases\n",
    "print(layer_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below represents the output of hidden layer in the figure above. There a 3 features in the sample which is indicated by the number of neurons in the input layer and thus, there are three scalar values in the input vector. There are 5 neurons in the hidden layer and each neuron in the layer has a unique connection with the neuron in the input layer. Therefore, the hidden layer will have a weight matrix consisting of 5 vectors with 5 scalar values of weights.\n",
    "\n",
    "To perform the matrix and vector dot product, the hidden layer weight matrix has to be transposed to align the shapes of input vector (The first matrix/vector must have the same number of columns as the rows of the second matrix). The output will be a vector of values for the layer to be used for the next layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.4  2.1  1.5 -0.2  5.3]\n"
     ]
    }
   ],
   "source": [
    "# Declare inputs ensuring the shape is the same as the weights matrix of the hidden layer neurons\n",
    "input_layer = [1.0, 2.0, 3.0]\n",
    "# Declare the weights for hidden layer neurons. Three weights per neuron as there are three unique connections per neuron\n",
    "hidden_layer_weights = [[0.1,0.2,0.3],\n",
    "                        [0.2,0.1,0.4],\n",
    "                        [0.1,-0.1,0.2],\n",
    "                        [-0.2,0.4,0.4],\n",
    "                        [0.1,0.3,0.2]]\n",
    "# Declare the biases for the hidden layer.  \n",
    "hidden_layer_biases = [2,0.5,1,-2,4]\n",
    "\n",
    "# Dot product of the transposed inputs matrix and weights matrix \n",
    "hidden_layer_output = np.dot(np.array(input_layer), np.array(hidden_layer_weights).T) + hidden_layer_biases\n",
    "print(hidden_layer_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output for the hidden layer above, can then be used as the input for the output layer. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "06d3ad103a38a5e5980b0a2ddf222334b9b3630c94a7e75a8e45e8afe280f469"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
