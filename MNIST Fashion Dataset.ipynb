{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST FASHION \n",
    "\n",
    "Fashion-MNIST is a dataset of Zalando's article imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. Zalando intends Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.\n",
    "\n",
    "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255. The training and test data sets have 785 columns. The first column consists of the class labels, and represents the article of clothing. The rest of the columns contain the pixel-values of the associated image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant modules for training the dataset\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Read training set using pandas\n",
    "df = pd.read_csv('fashion-mnist_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to plot a random sample from a dataset\n",
    "def plot_sample(dataset):\n",
    "    # Gather sample\n",
    "    sample = [dataset.iloc[np.random.randint(728), 1:]]\n",
    "    # Convert to numpy array and reshape it into a 28x28 matrix\n",
    "    sample = np.array([sample])\n",
    "    sample = sample.reshape((28,28))\n",
    "    # Plot the sample\n",
    "    plt.gray()\n",
    "    plt.imshow(sample, interpolation = 'nearest')\n",
    "    plt.show()\n",
    "\n",
    "# Call the function\n",
    "plot_sample(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the digit dataset, kaggle has provided a testing data set with labels to use for testing the model. There will be no need to split the dataset into two seperate dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, acc: 0.121, loss: 2.374, lr: 0.001\n",
      "epoch: 10, acc: 0.402, loss: 1.637, lr: 0.0009990109791306607\n",
      "epoch: 20, acc: 0.597, loss: 1.182, lr: 0.0009979143589897116\n",
      "epoch: 30, acc: 0.629, loss: 1.060, lr: 0.0009968201437414647\n",
      "epoch: 40, acc: 0.571, loss: 1.041, lr: 0.0009957283254836751\n",
      "epoch: 50, acc: 0.624, loss: 0.983, lr: 0.0009946388963486806\n",
      "epoch: 60, acc: 0.643, loss: 0.895, lr: 0.000993551848503214\n",
      "epoch: 70, acc: 0.670, loss: 0.845, lr: 0.000992467174148215\n",
      "epoch: 80, acc: 0.683, loss: 0.812, lr: 0.000991384865518643\n",
      "epoch: 90, acc: 0.696, loss: 0.785, lr: 0.0009903049148832926\n",
      "epoch: 100, acc: 0.707, loss: 0.764, lr: 0.0009892273145446092\n",
      "epoch: 110, acc: 0.715, loss: 0.747, lr: 0.0009881520568385063\n",
      "epoch: 120, acc: 0.722, loss: 0.732, lr: 0.0009870791341341834\n",
      "epoch: 130, acc: 0.730, loss: 0.718, lr: 0.0009860085388339465\n",
      "epoch: 140, acc: 0.737, loss: 0.705, lr: 0.0009849402633730264\n",
      "epoch: 150, acc: 0.742, loss: 0.693, lr: 0.000983874300219404\n",
      "epoch: 160, acc: 0.747, loss: 0.683, lr: 0.0009828106418736302\n",
      "epoch: 170, acc: 0.751, loss: 0.674, lr: 0.0009817492808686518\n",
      "epoch: 180, acc: 0.755, loss: 0.665, lr: 0.000980690209769636\n",
      "epoch: 190, acc: 0.759, loss: 0.655, lr: 0.0009796334211737967\n",
      "epoch: 200, acc: 0.764, loss: 0.648, lr: 0.0009785789077102233\n",
      "epoch: 210, acc: 0.767, loss: 0.641, lr: 0.0009775266620397072\n",
      "epoch: 220, acc: 0.770, loss: 0.635, lr: 0.0009764766768545735\n",
      "epoch: 230, acc: 0.774, loss: 0.628, lr: 0.0009754289448785103\n",
      "epoch: 240, acc: 0.777, loss: 0.621, lr: 0.0009743834588664023\n",
      "epoch: 250, acc: 0.776, loss: 0.616, lr: 0.000973340211604162\n",
      "epoch: 260, acc: 0.776, loss: 0.613, lr: 0.0009722991959085651\n",
      "epoch: 270, acc: 0.779, loss: 0.607, lr: 0.0009712604046270845\n",
      "epoch: 280, acc: 0.766, loss: 0.626, lr: 0.000970223830637728\n",
      "epoch: 290, acc: 0.781, loss: 0.597, lr: 0.0009691894668488743\n",
      "epoch: 300, acc: 0.783, loss: 0.593, lr: 0.0009681573061991112\n",
      "epoch: 310, acc: 0.786, loss: 0.587, lr: 0.000967127341657076\n",
      "epoch: 320, acc: 0.787, loss: 0.584, lr: 0.0009660995662212947\n",
      "epoch: 330, acc: 0.788, loss: 0.584, lr: 0.0009650739729200244\n",
      "epoch: 340, acc: 0.794, loss: 0.575, lr: 0.0009640505548110942\n",
      "epoch: 350, acc: 0.796, loss: 0.569, lr: 0.0009630293049817507\n",
      "epoch: 360, acc: 0.792, loss: 0.574, lr: 0.0009620102165484997\n",
      "epoch: 370, acc: 0.795, loss: 0.570, lr: 0.0009609932826569543\n",
      "epoch: 380, acc: 0.801, loss: 0.564, lr: 0.0009599784964816788\n",
      "epoch: 390, acc: 0.804, loss: 0.561, lr: 0.0009589658512260378\n",
      "epoch: 400, acc: 0.806, loss: 0.555, lr: 0.0009579553401220435\n",
      "epoch: 410, acc: 0.806, loss: 0.550, lr: 0.000956946956430205\n",
      "epoch: 420, acc: 0.804, loss: 0.549, lr: 0.000955940693439379\n",
      "epoch: 430, acc: 0.801, loss: 0.552, lr: 0.0009549365444666201\n",
      "epoch: 440, acc: 0.804, loss: 0.546, lr: 0.0009539345028570338\n",
      "epoch: 450, acc: 0.806, loss: 0.542, lr: 0.0009529345619836286\n",
      "epoch: 460, acc: 0.808, loss: 0.540, lr: 0.0009519367152471704\n",
      "epoch: 470, acc: 0.806, loss: 0.546, lr: 0.0009509409560760373\n",
      "epoch: 480, acc: 0.808, loss: 0.540, lr: 0.0009499472779260752\n",
      "epoch: 490, acc: 0.809, loss: 0.536, lr: 0.0009489556742804544\n",
      "epoch: 500, acc: 0.810, loss: 0.532, lr: 0.0009479661386495274\n"
     ]
    }
   ],
   "source": [
    "# Import NN classes \n",
    "from layer_dense import *\n",
    "from cost_functions import *\n",
    "from optimisers import *\n",
    "\n",
    "# Randomise df\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "# Create training dataset\n",
    "X_train = df.iloc[:,1:]\n",
    "y_train = df.iloc[:, 0]\n",
    "\n",
    "# Convert X into a numpy array and ramdomise the dataset\n",
    "X_train = np.array(X_train)\n",
    "\n",
    "# Initiate hidden layer with 784 input values and 10 neurons\n",
    "hidden_layer = LayerDense(784, 10)\n",
    "# Initiate ReLU activation object\n",
    "relu = ActivationRelU()\n",
    "# Initiate output layer with 10 input values and 10 neurons \n",
    "output_layer = LayerDense(10, 10)\n",
    "# Initate softmax and cost functions with the ActivationSoftmaxCost object\n",
    "softmax_cost = ActivationSoftmaxCost()\n",
    "\n",
    "# Initiate optimiser object for back propagation \n",
    "sgd = Optimizer_SGD(learning_rate=0.001 ,decay=1.1e-4, momentum=100)\n",
    "\n",
    "# Train in epochs. 501 iterations.\n",
    "for epoch in range(501):\n",
    "    # Forward propagation\n",
    "    hidden_layer.forward(X_train)\n",
    "    relu.forward(hidden_layer.output)\n",
    "    output_layer.forward(relu.output)\n",
    "    \n",
    "    # Calculate error\n",
    "    cost = softmax_cost.forward(output_layer.output, y_train)\n",
    "    \n",
    "    # Calculate accuracy from output of softmax and y\n",
    "    predictions = np.argmax(softmax_cost.output, axis=1)\n",
    "    accuracy = np.mean(predictions==y_train)\n",
    "    \n",
    "    # Print statistics per set of epochs\n",
    "    if not epoch % 10:\n",
    "        print(f'epoch: {epoch}, ' +\n",
    "              f'acc: {accuracy:.3f}, ' +\n",
    "              f'loss: {cost:.3f}, ' +\n",
    "              f'lr: {sgd.current_learning_rate}')\n",
    "        \n",
    "    # Back propagation \n",
    "    softmax_cost.backward(softmax_cost.output, y_train)\n",
    "    output_layer.backward(softmax_cost.dinputs)\n",
    "    relu.backward(output_layer.dinputs)\n",
    "    hidden_layer.backward(relu.dinputs)\n",
    "    \n",
    "    # Update weights and biases\n",
    "    sgd.pre_update_params()\n",
    "    sgd.update_params(hidden_layer)\n",
    "    sgd.update_params(output_layer)\n",
    "    sgd.post_update_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this dataset, the same model used for the digit MNIST data, achieved ~81% accuracy. This can be expected as identify chothes is more complex then identifying digits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, acc: 0.813, loss: 0.538\n"
     ]
    }
   ],
   "source": [
    "# Read test dataset\n",
    "df = pd.read_csv('fashion-mnist_test.csv')\n",
    "\n",
    "# Create testing dataset\n",
    "X_test = df.iloc[:,1:]\n",
    "y_test = df.iloc[:, 0]\n",
    "\n",
    "# Pass dataset through the model using the final params\n",
    "hidden_layer.forward(X_test)\n",
    "relu.forward(hidden_layer.output)\n",
    "output_layer.forward(relu.output)\n",
    "cost = softmax_cost.forward(output_layer.output, y_test)\n",
    "\n",
    "# Calculate accuracy and loss for the test dataset\n",
    "predictions = np.argmax(softmax_cost.output, axis = 1)\n",
    "# If y_test is a binary vector, convert to scalar values\n",
    "if len(y_test.shape) == 2:\n",
    "    y_test = np.argmax(y_test, axis = 1)\n",
    "accuracy = np.mean(predictions == y_test)\n",
    "\n",
    "# Print statistics\n",
    "print(f'test, acc: {accuracy:.3f}, loss: {cost:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be concluded that major overfitting hasn't occured with 82% accuracy on the testing dataset. \n",
    "\n",
    "The MNIST fashion dataset doesn't have unseen data where there are no labels, but the model can still be used with the testing dataset to demonstrate how accurate the model can be on single samples.\n",
    "\n",
    "The labels indicate a type of clothing by its corresponding number. A dictionary can be created to be used to give the prediction a string value rather than a integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model predicted the clothing is a Coat\n"
     ]
    }
   ],
   "source": [
    "# Create dictionary to get the type of clothing using a integer key.\n",
    "mnist_labels = {\n",
    "    0: \"T-shirt/top\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle boot\"\n",
    "}\n",
    "\n",
    "# Function to generate a random sample from a dataset\n",
    "def random_sample(dataset):\n",
    "    # Gather sample\n",
    "    sample = [dataset.iloc[np.random.randint(728), 1:]]\n",
    "    # Convert to numpy array and reshape it into a 28x28 matrix\n",
    "    sample_array = np.array([sample])\n",
    "    sample_array = sample_array.reshape((28,28))\n",
    "    # Plot the sample\n",
    "    return sample, sample_array\n",
    "\n",
    "# Plot random sample from the dataset\n",
    "sample, sample_array = random_sample(df)\n",
    "plt.imshow(sample_array, interpolation = 'nearest')\n",
    "plt.show()\n",
    "\n",
    "# Convert sample into an numpy array\n",
    "sample = np.array(sample)\n",
    "\n",
    "# Need the activation softmax class as we are no longer calculating error\n",
    "softmax = ActivationSoftmax()\n",
    "\n",
    "# Pass sample to initiate forward propagation\n",
    "hidden_layer.forward(sample)\n",
    "relu.forward(hidden_layer.output)\n",
    "output_layer.forward(relu.output)\n",
    "softmax.forward(output_layer.output)\n",
    "\n",
    "# Print prediction\n",
    "print(\"The model predicted the clothing is a\", mnist_labels[np.argmax(softmax.output)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When comparing the prediction with the plot sample, it is even hard to identify the sample to the correct label by eye. This is strong reason why the same model had lower accuracy compared to the digit dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
