{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Basics \n",
    "\n",
    "This notebook will go through the basics working of a neural network by using an example simple neural network in the figure below to illustrate concepts using code. The figure is simple neural network that has 3 layers: a input layer with 3 neurons, a hidden layer with 5 neurons and an output layer with two neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SimpleNeuralNetwork](https://miro.medium.com/max/1400/0*a_tr0gvjHtW9haUo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every neuron in each of the layers has a unique connection with the neurons in its adjacent layers. Neurons in a layer will take in values from the previous layer to produce an output for the next. The output is a multiplication of the inputs with the weight of the connection. Each neuron has a unique weight that corresponds to a unique connection and is multiplied with input value of the neuron that is connected.\n",
    "\n",
    "Below represents how the outer layer will produce its output values by using the input values from the hidden layer in the figure above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.5, 7.6499999999999995]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The below code is trying to replicate the output layer of the  neural network \n",
    "in the above figure.The inputs, weights and biases are arbituary.\n",
    " \"\"\"\n",
    "# Initialise the input values. 1 input value for each neuron\n",
    "inputs = [1.0, 2.0, 3.0, 4.0, 5.0] # There are five neurons in the hidden layer hence there are three input values.\n",
    "# Initialise the weights for each in the outer layer. \n",
    "# Each weight corresponds to a unique connection that the output layer neuron has\n",
    "weights1 = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "weights2 = [0.11, 0.21,0.31, 0.41, 0.51]\n",
    "# Initialise the bias values for each output neuron\n",
    "bias1 = 1\n",
    "bias2 = 2\n",
    "\"\"\"\n",
    "The output values for the hidden layer will be multiplication of the values of \n",
    "the  neurons in hidden/previous layer. The output will be a list of 2 values\n",
    "that corresponds to the value of the neuron in that layer\n",
    "\"\"\"\n",
    "# Calculate the values for the output layer\n",
    "output = [\n",
    "inputs[0]*weights1[0] + inputs[1]*weights1[1] + inputs[2]*weights1[2] + \\\n",
    "inputs[3]*weights1[3] + inputs[4]*weights1[4] + bias1,\n",
    "inputs[0]*weights2[0] + inputs[1]*weights2[1] + inputs[2]*weights2[2] + \\\n",
    "inputs[3]*weights2[3] + inputs[4]*weights2[4] + bias2 \n",
    "]\n",
    "\n",
    "# Print out the value of the outer layer\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outer layer produced two values that belongs to each neuron in its layer. A cleaner code is written below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.5, 7.6499999999999995]\n"
     ]
    }
   ],
   "source": [
    "inputs = [1.0, 2.0, 3.0, 4.0, 5.0]\n",
    "# Weights is a 2D array of values that belong to each neuron in the outer layer\n",
    "weights = [[0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "          [0.11, 0.21,0.31, 0.41, 0.51]]\n",
    "# Both bias values is now in the same list\n",
    "biases = [1,2]\n",
    "\n",
    "# Initialise values for output layer\n",
    "layer_outputs = []\n",
    "# Loop through the set of weights and each bias values declared above\n",
    "for neuron_weights, neuron_bias in zip(weights, biases):\n",
    "    neuron_output = 0 # Initialise neuron value\n",
    "# Loop throught inputs declared above and neuron_weights for each neuron\n",
    "    for n_input, weight in zip(inputs, neuron_weights):\n",
    "# Increment neuron_output by the multiplication of input and weight\n",
    "        neuron_output += n_input * weight\n",
    "# Increment neuron_output by the bias\n",
    "    neuron_output += neuron_bias\n",
    "# Append layer_outputs with the final neuron_output value\n",
    "    layer_outputs.append(neuron_output)\n",
    "\n",
    "print(layer_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example above multiplies the corresponding inputs and weights to produce an output. In a real neural network, the mutiplication will be dot product.\n",
    "\n",
    "The inputs variable is 1 dimensional and is a vector. The weights is 2 dimensional and is a matrix. Multiplying both is called the dot product. The code will now look like this below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.5  7.65]\n"
     ]
    }
   ],
   "source": [
    "# Import numpy to handle arrays\n",
    "import numpy as np\n",
    "\n",
    "# Weights comes first as the argument due to shape. You can't multiply a vector with a matrix.\n",
    "layer_outputs = np.dot(weights, inputs) + biases\n",
    "print(layer_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example, the input layer is a vector representing one sample. To train an neural network multiple samples or vectors is needed. The code below uses a matrix (multiple vectors), as the input layer. To multiply two matrixes, the first matrix must have the same number of columns as the second matrix has rows. If both matrix share the same number of rows, one of the matrix will need to be transposed.\n",
    "\n",
    "The code below illustrates the input having multiple samples in its matrix. The weight matrix will need to be tranposed so that the matrixes can be transposed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.5  1.8  3.2  0.5  7.4]\n",
      " [ 3.6  1.8  2.4 -1.9  4.7]\n",
      " [ 6.5  2.1  3.7 -0.5  6.7]\n",
      " [ 1.7 -0.6  0.7 -3.4  5.1]]\n"
     ]
    }
   ],
   "source": [
    "# Declare inputs ensuring the shape is the same as the weights matrix of the hidden layer neurons\n",
    "input_layer = [[1.0, 2.0, 3.0, 4.0, 5.0],\n",
    "               [2.0, -2.0, 3.0, 1.0, 1.0],\n",
    "               [1.0, -1.0, 5.0, 4.0, 3.0],\n",
    "               [2.0, 3.0, -3.0, 2.0, -2.0]]\n",
    "# Declare the weights for hidden layer neurons. Three weights per neuron as there are three unique connections per neuron\n",
    "hidden_layer_weights = [[0.1,0.2,0.3,0.4,0.5],\n",
    "                        [0.2,0.1,0.4,-0.2,0.1],\n",
    "                        [0.1,-0.1,0.2,0.3,0.1],\n",
    "                        [-0.2,0.4,0.4,-0.2,0.3],\n",
    "                        [0.1,0.3,0.2,0.4,0.1]]\n",
    "# Declare the biases for the hidden layer.  \n",
    "hidden_layer_biases = [2,0.5,1,-2,4]\n",
    "\n",
    "# Dot product of the transposed inputs matrix and weights matrix \n",
    "hidden_layer_output = np.dot(input_layer, np.array(hidden_layer_weights).T) + hidden_layer_biases\n",
    "print(hidden_layer_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output for the hidden layer above, can then be used as the input for the output layer. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
